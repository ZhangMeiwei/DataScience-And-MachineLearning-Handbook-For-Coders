# 概率论
概率论是用于表示不确定陈述（Statement）的数学框架，它提供了量化不确定性的方法，使我们能够做出不确定的陈述以及在不确定性存在的情况下的推理；而信息论使我们能够量化概率分布中的不确定性总量。

# Probability
>  Probability theory is nothing but common sense reduced to calculation. ——Pierre Laplace

概率论是机器学习中的重要角色，那么何谓概率？我们在小学里就听老师讲过抛硬币时正面朝上的概率为0.5，这句话又代表着何含义呢？对于概率的理解往往有两种不同的方式，其一是所谓的频率论解释（Frequentist Interpretation）。这种观点中，概率代表着某个事件在较长范围内的出现频次。譬如这里的抛硬币问题可以阐述为，如果我们抛足够的次数，我们会观测到正面朝上的次数与反面朝上的次数基本相同。另一种即时所谓的贝叶斯解释（Bayesian Interpretation），我们认为概率是用来衡量某件事的不确定性（uncertainty），其更多地与信息相关而不再是重复尝试的次数。用贝叶斯理论阐述抛硬币问题则为下一次抛硬币时正面朝上的可能性与反面朝上的可能性相差无几。贝叶斯解释的最大优势在于我们可以去为事件的不确定性建立具体的模型而不再依赖于多次试验得出的频次结果。譬如我们要去预测2020年世界杯的冠军，我们肯定不能让球队比赛很多次来观测频次计算概率，这件事只会发生零或一次，反正是无法重复发生的。基于贝叶斯理论我们便可以利用可观测到的数据推测该事件的结果概率，典型的应用是垃圾邮件过滤系统中，我们可以根据带标签的训练数据来对新的邮件进行判断。

# Random Variables:随机变量

# Independence & Conditional Independence: 独立与条件独立

## 独立性检验
卡方分析有两个常见的应用——适合度分析和独立性分析。这个笔记着重于适合度分析。从我目前的经验来看，这也是应用十分广泛的一种统计分析方式。那么什么是卡方适合度分析呢？且听我慢慢道来。

|      | 现象1  | 现象2  | 现象3  |
| ---- | ---- | ---- | ---- |
| 观测值  | a    | b    | c    |
| 预期值  | A    | B    | C    |

常见的适合度分析的结构如下，一般有两组数据，一组是你统计或者观察到的值，另一组是理论上的预期值。如果这两组值十分接近，证明观测到的结果很“合适”，如果差距较大，则证明观测到的数据不够“合适”，这就是“适合度分析”名字的含义。

![](http://img.blog.csdn.net/20161007084653850?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

这种统计分析在科学研究中是十分常用的，因为科学家经常按照理论预期来推测试验结果，而实际上由于各种误差的存在，实验数据不可能和理论预期完全一致，这时卡方检验就能很好地检验理论的正确性。

```
from scipy import stats
obs = [102, 102, 96, 105, 95, 100]
exp = [100, 100, 100, 100, 100, 100]
stats.chisquare(obs, f_exp = exp)
```
![](http://img.blog.csdn.net/20161007085433109?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)


# Mean & Variance:均值与方差